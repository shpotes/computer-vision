{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "#from classic_network import LeNet_5, AlexNet, VGG16\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "def prepros(x, y, INPUT_SIZE=(32, 32, 1)):\n",
    "    N = y.size\n",
    "    x = np.pad(x, ((0,0),(2,2),(2,2)), 'constant').reshape((N, *INPUT_SIZE))\n",
    "    y_ = np.zeros((N, 10))\n",
    "    y_[np.arange(N), y] = 1\n",
    "    return x, y_\n",
    "\n",
    "x_train, y_train = prepros(x_train, y_train)\n",
    "x_test, y_test = prepros(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LeNet5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "C1 (Conv2D)                  (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "S2 (SubPooling)              (None, 14, 14, 6)         12        \n",
      "_________________________________________________________________\n",
      "C3 (Conv2D)                  (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "S4 (SubPooling)              (None, 5, 5, 16)          32        \n",
      "_________________________________________________________________\n",
      "C5 (Conv2D)                  (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "F5 (Flatten)                 (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "F6 (Dense)                   (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "F7 (Dense)                   (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,750\n",
      "Trainable params: 61,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Activation\n",
    "from layers import SubPooling\n",
    "\n",
    "A = tf.constant(1.7159)\n",
    "S = tf.constant(2/3)\n",
    "\n",
    "LeNet_5 = tf.keras.models.Sequential([\n",
    "    Conv2D(name='C1',\n",
    "           filters=6,\n",
    "           kernel_size=(5, 5),\n",
    "           strides=(1, 1),\n",
    "           padding='valid',\n",
    "           input_shape=(32, 32, 1)),\n",
    "\n",
    "    SubPooling(name='S2',\n",
    "               features=6),\n",
    "    \n",
    "    Conv2D(name='C3',\n",
    "           filters=16,\n",
    "           kernel_size=(5, 5),\n",
    "           strides=(1, 1),\n",
    "           padding='valid'),\n",
    "    \n",
    "    SubPooling(name='S4',\n",
    "               features=16),\n",
    "    \n",
    "    Conv2D(name='C5',\n",
    "           filters=120,\n",
    "           kernel_size=(5, 5),\n",
    "           strides=(1, 1),\n",
    "           padding='valid'),\n",
    "    \n",
    "    Flatten(name='F5'),\n",
    "    \n",
    "    Dense(name='F6',\n",
    "          units=84,\n",
    "          activation=Activation(lambda x: A * tf.nn.tanh(S*x))),\n",
    "    \n",
    "    Dense(name='F7',\n",
    "          units=10,\n",
    "          activation='softmax')\n",
    "        \n",
    "], name='LeNet5')\n",
    "\n",
    "LeNet_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet_5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "60000/60000 [==============================] - 51s 842us/sample - loss: 0.2593 - accuracy: 0.9164 - val_loss: 0.1369 - val_accuracy: 0.9548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f72ac5b1a90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "LeNet_5.fit(x_train, y_train,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_image_dataset\n",
    "\n",
    "TRAIN = 'imagenet12/train/'\n",
    "TEST = 'imagenet12/test/'\n",
    "VAL = 'imagenet12/val/'\n",
    "\n",
    "train, N = read_image_dataset(TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 62,378,344\n",
      "Trainable params: 62,378,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "\n",
    "AlexNet = tf.keras.models.Sequential([\n",
    "    Conv2D(filters=96,\n",
    "           kernel_size=(11, 11),\n",
    "           strides=(4, 4),\n",
    "           padding='valid',\n",
    "           activation='relu',\n",
    "           input_shape=(227, 227, 3)),\n",
    "    \n",
    "    MaxPool2D(pool_size=(3, 3),\n",
    "              strides=(2, 2),\n",
    "              padding='valid'),\n",
    "    \n",
    "    Conv2D(filters=256,\n",
    "           kernel_size=(5, 5),\n",
    "           strides=(1, 1),\n",
    "           padding='same',\n",
    "           activation='relu'),\n",
    "    \n",
    "    MaxPool2D(pool_size=(3, 3),\n",
    "              strides=(2, 2),\n",
    "              padding='valid'),\n",
    "    \n",
    "    Conv2D(filters=384,\n",
    "           kernel_size=(3, 3),\n",
    "           strides=(1, 1),\n",
    "           padding='same',\n",
    "           activation='relu'),\n",
    "    \n",
    "    Conv2D(filters=384,\n",
    "           kernel_size=(3, 3),\n",
    "           strides=(1, 1),\n",
    "           padding='same',\n",
    "           activation='relu'),\n",
    "    \n",
    "    Conv2D(filters=256,\n",
    "           kernel_size=(3, 3),\n",
    "           strides=(1, 1),\n",
    "           padding='same',\n",
    "           activation='relu'),    \n",
    "    \n",
    "    MaxPool2D(pool_size=(3, 3),\n",
    "              strides=(2, 2),\n",
    "              padding='valid'),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1000, activation='softmax')\n",
    "])\n",
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WD = 5e-4 / 2\n",
    "BS = 128\n",
    "Mom = 0.9\n",
    "LR = 1e-2\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = tf.keras.regularizers.l2(WD)\n",
    "for layer in AlexNet.layers:\n",
    "    if hasattr(layer, 'kernel_regularizer'):\n",
    "        setattr(layer, 'kernel_regularizer', regularizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = tf.keras.optimizers.SGD(lr=LR, momentum=Mom)\n",
    "AlexNet.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='logs/alexnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train = train.shuffle(buffer_size=N)\n",
    "train = train.batch(BS).prefetch(buffer_size=AUTOTUNE)\n",
    "SPE =tf.math.ceil(N/BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "AlexNet.fit(train, epochs=EPOCHS, steps_per_epoch=SPE, callbacks=[tensorboard])\n",
    "tf.keras.models.save_model(AlexNet, 'alexnet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Crop ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 224, 224, 3])\n",
    "y = tf.placeholder(tf.int32, shape=[None])\n",
    "one_hot_y = tf.one_hot(y, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 256\n",
    "Mom = 0.9\n",
    "LR = 1e-2\n",
    "logits = VGG16(x)\n",
    "cost = tf.losses.softmax_cross_entropy(one_hot_y, logits)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=LR,\n",
    "                                       momentum=Mom)\n",
    "training = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, shape=[None])\n",
    "one_hot_y = tf.one_hot(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResBlock\n",
    "\n",
    "w1 = tf.Variable(tf.truncated_normal([3, 3, 3, 16], stddev=tf.sqrt(2/(3 * 3 * 3))))\n",
    "w2 = tf.Variable(tf.truncated_normal([1024, 10], stddev=tf.sqrt(2/1024)))\n",
    "b1 = tf.Variable(tf.zeros(16))\n",
    "b2 = tf.Variable(tf.zeros(10))\n",
    "\n",
    "z1 = tf.nn.conv2d(input=x, filter=w1, strides=[1, 1, 1, 1], padding='SAME') + b1\n",
    "a1 = tf.nn.relu(tf.layers.batch_normalization(z1))\n",
    "\n",
    "#r2 = ResBlock(ResBlock(ResBlock(a1)))\n",
    "#r3 = ResBlock(ResBlock(ResBlock(r2, bottleneck=True)))\n",
    "#r4 = ResBlock(ResBlock(ResBlock(r3, bottleneck=True)))\n",
    "\n",
    "\n",
    "w2T = tf.Variable(tf.truncated_normal([32, 32, 16, 16], stddev=tf.sqrt(2/(32 * 32 * 16))))\n",
    "b2T = tf.Variable(tf.zeros(16))\n",
    "\n",
    "z2 = tf.nn.conv2d(input=a1, filter=w2T, strides=[1, 1, 1, 1], padding='SAME') + b2T\n",
    "a2 = tf.nn.relu(tf.layers.batch_normalization(z2))\n",
    "\n",
    "#r2T = ResBlock(a1, plain=True)\n",
    "#s3T = tf.nn.max_pool(r2T, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "#r4T = ResBlock(ResBlock(s3T, plain=True), plain=True)\n",
    "#s5T = tf.nn.max_pool(r4T, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "\n",
    "\n",
    "s5T = tf.nn.max_pool(a2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "#f5 = tf.reshape(s5T, [-1, 16 * 16 * 16])\n",
    "\n",
    "inp = 16 * 16 * 16\n",
    "f5 = tf.reshape(s5T, [-1, inp])\n",
    "\n",
    "w2T = tf.Variable(tf.truncated_normal([inp, 1024], stddev=tf.sqrt(2/inp)))\n",
    "b2T = tf.Variable(tf.zeros(1024))\n",
    "f6 = tf.nn.relu(tf.layers.batch_normalization(tf.nn.dropout(tf.matmul(f5, w2T) + b2T, keep_prob=0.5)))\n",
    "\n",
    "w3T = tf.Variable(tf.truncated_normal([1024, 10], stddev=tf.sqrt(2/1024)))\n",
    "b3T = tf.Variable(tf.zeros(10))\n",
    "logits = tf.nn.softmax(tf.matmul(f6, w3T) + b3T)\n",
    "\n",
    "#r3T = ResBlock(ResBlock(a1, plain=True), plain=True)\n",
    "\n",
    "#s5 = tf.nn.avg_pool(r4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "#f5 = tf.reshape(s5, [-1, 4 * 4 * 64])\n",
    "#f6 = tf.matmul(f5, w2) + b2\n",
    "#logits = tf.nn.softmax(f6)\n",
    "#s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "WD = 0.0001\n",
    "M = 0.9\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "pred = tf.argmax(logits, axis=-1)\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_y,\n",
    "                                                logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.contrib.opt.MomentumWOptimizer(weight_decay=WD, learning_rate=LR, momentum=M)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(pred, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32)) * 100\n",
    "\n",
    "tf.summary.scalar('acc_summary', accuracy)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1563 [00:23<2:35:19,  5.98s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ecbf1a87c057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "STORE_PATH = 'logs/'\n",
    "saver = tf.train.Saver()\n",
    "ws = {}\n",
    "N = 3125\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(STORE_PATH, sess.graph)\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        x_train, y_train = shuffle(x_train, y_train)\n",
    "        for offset in tqdm(range(0, y_train.size, BATCH_SIZE)):\n",
    "            end = offset + BATCH_SIZE\n",
    "            xt, yt = x_train[offset:end], y_train[offset:end]\n",
    "            sess.run(train_op, feed_dict={x: xt, y: yt})\n",
    "            \n",
    "        loss_v, acc, summary = sess.run([loss, accuracy, merged], feed_dict={x: xt, y: yt})\n",
    "        print(\"Epoach {}, Minibatch Loss= {:.4f}, Training Accuracy={:.2f}%\".format(i, loss_v, acc))\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    save_path = saver.save(sess, \"logs/resnet.ckpt\")\n",
    "\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: x_test,\n",
    "                                      y: y_test}))\n",
    "    ws = sess.run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
